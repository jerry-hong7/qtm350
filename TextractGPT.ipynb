{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb46294-7a3e-4e43-a4ac-38d160bd0d60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install openai==0.28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1f38b08f-feec-4e6d-a355-59809b63123d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import packages\n",
    "import boto3\n",
    "import openai\n",
    "import os\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03c1d7bd-ab66-4094-92aa-3bcbf9c9801d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# textract for both pdfs and image files (jpg/png)\n",
    "\n",
    "def top_file(bucket_name, file_extension=\".pdf\"):\n",
    "    s3 = boto3.client('s3')\n",
    "    response = s3.list_objects_v2(Bucket=bucket_name)\n",
    "\n",
    "    # Check if the bucket is not empty\n",
    "    if 'Contents' in response and response['Contents']:\n",
    "        # Filter files by the specified extension and sort by last modified timestamp\n",
    "        filtered_files = [obj for obj in response['Contents'] if obj['Key'].lower().endswith(file_extension.lower())]\n",
    "        if filtered_files:\n",
    "            most_recent_file = max(filtered_files, key=lambda x: x['LastModified'])\n",
    "            return most_recent_file['Key']\n",
    "    \n",
    "    return None\n",
    "\n",
    "def start_text(bucket_name, document_key):\n",
    "    textract = boto3.client('textract')\n",
    "\n",
    "    # Check the file extension to determine the appropriate method\n",
    "    file_extension = document_key.split('.')[-1].lower()\n",
    "\n",
    "    if file_extension == 'pdf':\n",
    "        response = textract.start_document_text_detection(\n",
    "            DocumentLocation={\n",
    "                'S3Object': {\n",
    "                    'Bucket': bucket_name,\n",
    "                    'Name': document_key\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "    elif file_extension in ['jpg', 'jpeg', 'png']:\n",
    "        response = textract.start_document_text_detection(\n",
    "            DocumentLocation={\n",
    "                'S3Object': {\n",
    "                    'Bucket': bucket_name,\n",
    "                    'Name': document_key\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported file type: {file_extension}\")\n",
    "\n",
    "    # Get the JobId for checking the analysis status\n",
    "    job_id = response['JobId']\n",
    "    return job_id\n",
    "\n",
    "def get_text(job_id):\n",
    "    textract = boto3.client('textract')\n",
    "    response = None\n",
    "    while response is None or response['JobStatus'] == 'IN_PROGRESS':\n",
    "        response = textract.get_document_text_detection(JobId=job_id)\n",
    "        \n",
    "    return response\n",
    "\n",
    "def extract_text(response):\n",
    "    # Extract the detected text from the response\n",
    "    detected_text = \"\"\n",
    "    for page_result in response['Blocks']:\n",
    "        if page_result['BlockType'] == 'LINE':\n",
    "            detected_text += page_result['Text'] + \"\\n\"\n",
    "\n",
    "    return detected_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ef347d01-4d94-446e-b20b-b10ba6bfed78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pass the textract string to GPT\n",
    "\n",
    "def api_key_s3(bucket, key_file):\n",
    "    s3 = boto3.client('s3')\n",
    "    obj = s3.get_object(Bucket=bucket, Key=key_file)\n",
    "    return obj['Body'].read().decode('utf-8').strip()\n",
    "\n",
    "def chatgpt_to_s3(api_key_bucket, api_key_file, extracted_text, Output_Bucket, file):\n",
    "    api_key = api_key_s3(api_key_bucket, api_key_file)\n",
    "    openai.api_key = api_key\n",
    "       \n",
    "    prompt = f\"Summarize these notes in a Study Guide:\\n{extracted_text}.\"\n",
    "    \n",
    "    response = openai.ChatCompletion.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                messages=[{'role': 'user', 'content': prompt}]\n",
    "            )\n",
    "    output = response['choices'][0]['message']['content'].strip()\n",
    "\n",
    "    output_filename = file.replace('.', '_') + '_summary.txt'\n",
    "    output_bytes = io.BytesIO(output.encode())\n",
    "\n",
    "    s3.upload_fileobj(output_bytes, Output_Bucket, output_filename)\n",
    "\n",
    "    print(f\"The Study Guide is Located in {Output_Bucket}/{output_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "80ba4cf0-20a1-4938-bc70-d5506875fb9b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most recent file in the bucket: Tuberous Sclerosis Complex Notes.pdf\n",
      "Text detection job submitted. JobId: 7d36a8ad50cbaf27e79bd4677ff96ab0bf474c17639b0462d74cec9064f56587\n",
      "The Study Guide is Located in gpt-summaries/Tuberous Sclerosis Complex Notes_pdf_summary.txt\n"
     ]
    }
   ],
   "source": [
    "# initialize main function\n",
    "\n",
    "api_key_bucket = 'gpt-api-bucket'\n",
    "api_key_file = 'GPTKey2.txt'\n",
    "Output_Bucket = 'gpt-summaries'\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    bucket_name = 'textract-assets'\n",
    "\n",
    "    # Get the most recent file from the bucket\n",
    "    file = top_file(bucket_name)\n",
    "\n",
    "    if most_recent_file:\n",
    "        print(f\"Most recent file in the bucket: {file}\")\n",
    "\n",
    "        job_id = start_text(bucket_name, file)\n",
    "        print(f\"Text detection job submitted. JobId: {job_id}\")\n",
    "\n",
    "        # Retrieve the results\n",
    "        response = get_text(job_id)\n",
    "\n",
    "        # Extract text from the document\n",
    "        detected_text = extract_text(response)\n",
    "        \n",
    "        # pass to GPT\n",
    "        chatgpt_to_s3(api_key_bucket, api_key_file, detected_text, Output_Bucket, file)\n",
    "            \n",
    "    else:\n",
    "        print(\"The S3 bucket is empty.\")\n",
    "        \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
